\section[Estado del Arte]{CAPÍTULO 2:$\ \ \ \ $ESTADO DEL ARTE} 

En los últimos años se ha registrado un marcado desarrollo y progreso en el campo de el procesamiento de señales del habla. En este campo, la dereverberación ocupa un rol crucial, debido al impacto negativo que genera la presencia de reverberación en muchas aplicaciones del procesamiento de señales de habla. 

Los primeros enfoques que apuntaron a resolver el problema de la dereverberación se orientaron al modelado o registro de las respuestas al impulso y la estimación de filtros inversos a partir de estas \cite{filtros_inv}. Como el efecto de la reverberación en una señal se puede pensar como el resultado de una convolución entre una señal anecoica y una respuesta al impulso, este enfoque apunta a estimar la respuesta al impulso con el fin de poder generar un filtro inverso que permita realizar una deconvolución de la señal para poder revertir el efecto de la respuesta del recinto, recuperando la señal en su estado anecoico. Sin embargo, esta metodología presenta varios inconvenientes, como el hecho de considerar que las respuestas al impulso son lineales e invariantes en el tiempo, lo cual no siempre se cumple en la práctica \cite{LTI}, o bien el hecho de que la respuesta no siempre pueda ser deducida de manera directa y deba ser estimada. 


También surgieron trabajos enfocados en modelar matemáticamente la señal de habla anecoica  \cite{rabiner}. Algunos de estos trabajos consistían en estimar la señal de habla mediante predicción lineal, y calcular el residuo, el cual contiene información sobre la reverberación en la señal. Esta señal de residuo se utilizó para estimar filtros variantes en el tiempo que al aplicarse a la señal de habla lograban eliminar parte de la reverberación \cite{LPresiduo}. Otro enfoque consistió en utilizar múltiples transductores y aplicar técnicas de factorización matricial, como la descomposición en valores singulares (SVD), sobre las señales captadas \cite{multichannel}. Algunas características propias de las señales de habla, como la estructura armónica \cite{armonica} y el índice de modulación  \cite{mod}, fueron explotadas para eliminar los efectos de la reverberación. 

Posteriormente, se aplicó la idea de la sustracción espectral \cite{spect_subtrac} \cite{spect_subtrac2} que básicamente consiste en la estimación del espectro de potencia generado por la reverberación a partir de modelos estadísticos. En 2006, Wang et. al. aplicaron este enfoque combinado con el de la estimación de filtros inversos logrando presentar avances importantes en la efectividad de los algoritmos \cite{two_stage}.
 
 
El uso de máscaras binarias ideales en el dominio temporal-frecuencial para extraer las señales buscadas \cite{binarymask} es un enfoque muy utilizado, el cual tiene su origen en el campo del análisis computacional de escenas auditivas \cite{ASA}. Las máscaras se definen como ideales ya que su obtención requieren del conocimiento de la señal buscada y de la señal que interfiere. El uso de estas máscaras implica primero realizar una transformación de la señal de entrada de manera de trasladarla al dominio tiempo-frecuencia (por ejemplo un espectrograma, o un cocleograma) y luego asignarle a cada punto del espacio temporal-frecuencial un valor de 1 cuando su energía mayormente pertenece a la señal objetivo, y un valor de 0 en el caso contrario. Roman et. al. \cite{rev_mask} aplicaron este concepto para tratar el problema de dereverberación, donde se busca estimar la máscara binaria ideal tomando como señal objetivo la señal del habla en condiciones anecoicas y como interferencia a la parte reverberante. Para conseguir la dereverberación, este método requiere seleccionar de manera correcta parámetros como el punto desde el cual se distingue la parte temprana y tardía de la reverberación,y el nivel del umbral en base al cual se identifica a un punto específico como parte de la señal deseada o de la interferencia \cite{parametros}. Hazrati et al. \cite{hazrati} propusieron estimar la máscara binaria a partir de un parámetro dependiente de la varianza de la señal, la cual define un umbral adaptativo, obteniendo mejores resultados. 

A partir del año 2007, se comenzaron a aplicar redes neuronales en la tarea de dereverberación. Jin y Wang \cite{MLP} utilizaron perceptrones multicapa para estimar las mascaras binarias necesarias para la separación de la componente reverberante en una señal voz. La red neuronal aprende a estimar máscaras binarias a partir de la representación tiempo-frecuencia de la señal reverberada. Mas adelante, con el avance de los modelos de aprendizaje profundo, esta técnica se iría perfeccionando reflejándose en mejores resultados en la tarea de dereverberación. Los enfoques basados en la estimación de máscaras tuvieron variantes como por ejemplo la estimación de máscaras ideales reales \cite{cIRM}, mascaras ideales complejas \cite{IRM} y mascaras sensibles a la fase \cite{GAN}.
  
En 2014 Kun et al. \cite{ezeKun} proponen el uso de redes neuronales profundas para aprender el mapeo espectral de señales reverberantes hacia señales anecoicas. Esto quiere decir, en otras palabras, que se entrena una red neuronal profunda para que sea capaz de estimar el espectro anecoico a partir de la señal reverberada. Nuevamente se vuelve al planteo de la búsqueda del filtro inverso que permita la deconvolución de la señal reverberante para obtener su versión anecoica, pero en este caso se utilizaran redes neuronales para estimar ese filtro. 

Se han explorado una gran cantidad de arquitecturas y tipos de redes neuronales profundas. Las más utilizadas son las redes neuronales convolucionales (CNN), que surgieron del estudio de la corteza visual del cerebro y han sido muy exitosas en algunas tareas visuales complejas \cite{lagartija}.  Las CNN en general trabajan sobre espectrogramas de magnitud y tienen una estructura de codificador-decodificador \cite{FCN, rir_filtinverso}. Estas son eficientes en términos de parámetros, aunque requieren de una gran cantidad de capas (o profundidad). Esto se debe a que cada capa convolucional modela su entrada de forma local, con un campo receptivo limitado, y es necesario colocar muchas capas en serie para ampliar ese campo receptivo y abarcar la totalidad del espectrograma de entrada. 

Otro enfoque es utilizar redes neuronales que modelen el espectrograma de forma global, como es el caso de las redes recurrentes \cite{RNN}. Estas permiten aprovechar el contexto temporal de una secuencia de datos, por lo cual pueden extraer estructuras de corto y largo término, solucionando problemas asociados a las arquitecturas convolucionales como la discontinuidad entre espectrogramas.


También se implementaron sistemas que combinan dos o más arquitecturas. Por ejemplo, la combinación de redes convolucionales y redes recurrentes \cite{RNN+CNN}. De esta manera, la red convolucional permite analizar características locales en un contexto temporal fijo, y la red recurrente permite conservar información estructural de largo plazo. Otro ejemplo es la combinación de redes convolucionales y recurrentes con redes generativas adversarias (GAN) \cite{GAN}, lo cual produce una mejora en la calidad percibida del audio dereverberado generado. 

Gran parte de los trabajos procesan la magnitud del espectrograma, ignorando la información de fase. En estos casos, al realizar la inversión del espectrograma estimado, algunos sistemas \cite{ezeKun} utilizan el algoritmo de Griffin Lim \cite{griffinlim}, el cual permite invertir espectrogramas utilizando solamente su magnitud. Otros trabajos utilizan la fase original de la señal reverberada \cite{CNN, FCN, skip, rir_filtinverso}, lo cual es una solución sencilla aunque subóptima. Por último, en trabajos recientes la información de fase es utilizada por las redes neuronales, ya sea porque trabajan con el espectrograma complejo \cite{cIRM}, o porque modelan directamente la forma de onda \cite{hifiGAN}.